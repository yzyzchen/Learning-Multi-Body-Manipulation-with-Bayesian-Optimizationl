(tensor) yuzhou@Yuzhous-MacBook-Pro-8 bayesian_opt_multi_dynamic % python multi_dynamic_main.py opt_demo_model
pybullet build time: Nov  5 2024 13:54:07

=== Load the model and run the demo with bayes optimization===
argv[0]=--opengl2
/Users/yuzhou/Desktop/bayesian_opt_multi_dynamic/optimizer/panda_pushing_optimizer.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self._dynamics_model.load_state_dict(torch.load(BOX_MULTI_RESIDUAL_MODEL))
Testing box pushing optimizer with fixed target for 20 epochs
target state:  [ 0.95 -0.1   0.  ]
0.37073034427374457
goal dist:  0.09566313882166748
--------------------------------------------------
COST: 1.4957
STEP: 14
GOAL: True
MIN COST: 1.4957
PARAM: ['0.0324', '0.9824', '0.2059', '0.8993']
target state:  [ 0.95 -0.1   0.  ]
0.14246912440558546
goal dist:  0.09198094239157116
--------------------------------------------------
COST: 1.2920
STEP: 12
GOAL: True
MIN COST: 1.2920
PARAM: ['0.0324', '0.9824', '0.2059', '0.8993']
target state:  [ 0.95 -0.1   0.  ]
-0.36344138532291015
goal dist:  0.08923613291825551
--------------------------------------------------
COST: 1.1892
STEP: 11
GOAL: True
MIN COST: 1.1892
PARAM: ['0.0324', '0.9824', '0.2059', '0.8993']
target state:  [ 0.95 -0.1   0.  ]
0.3327708633222912
goal dist:  0.0852485260334355
--------------------------------------------------
COST: 1.0852
STEP: 10
GOAL: True
MIN COST: 1.0852
PARAM: ['0.0324', '0.9824', '0.2059', '0.8993']
target state:  [ 0.95 -0.1   0.  ]
-0.4931383147643766
goal dist:  0.0942965157834995
--------------------------------------------------
COST: 0.9943
STEP: 9
GOAL: True
MIN COST: 0.9943
PARAM: ['0.0324', '0.9824', '0.2059', '0.8993']
target state:  [ 0.95 -0.1   0.  ]
0.15363606683274622
goal dist:  0.10840487941131682
--------------------------------------------------
COST: 1.2084
STEP: 11
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
-0.006898892363655036
goal dist:  0.09450889758667086
--------------------------------------------------
COST: 1.3945
STEP: 13
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
0.4539847900713733
detached, done with this trajectory
goal dist:  0.23090402945447328
--------------------------------------------------
COST: 12.4309
STEP: 22
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
0.1319218746165012
goal dist:  0.09573948302393256
--------------------------------------------------
COST: 1.2957
STEP: 12
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
-0.47610065180984057
goal dist:  0.09906915268468436
--------------------------------------------------
COST: 1.1991
STEP: 11
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
0.034275596950906255
goal dist:  0.09256513337748185
--------------------------------------------------
COST: 1.3926
STEP: 13
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
-0.1479091028122645
detached, done with this trajectory
goal dist:  0.26549568990213096
--------------------------------------------------
COST: 14.0655
STEP: 38
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
-0.1447158224869257
goal dist:  0.1030230854473089
--------------------------------------------------
COST: 1.3030
STEP: 12
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
-0.03351533813974474
goal dist:  0.09379427408838686
--------------------------------------------------
COST: 1.0938
STEP: 10
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
-0.082790444427075
goal dist:  0.09360976713647384
--------------------------------------------------
COST: 1.2936
STEP: 12
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
-0.43346771284963703
goal dist:  0.08245627631882382
--------------------------------------------------
COST: 1.1825
STEP: 11
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
-0.37469823068107094
goal dist:  0.08787101678370153
--------------------------------------------------
COST: 0.9879
STEP: 9
GOAL: True
MIN COST: 0.9879
PARAM: ['0.0324', '0.9824', '0.2059', '0.8993']
target state:  [ 0.95 -0.1   0.  ]
0.032891737831018716
goal dist:  0.09811628144286709
--------------------------------------------------
COST: 1.6981
STEP: 16
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
-0.33602968014385337
goal dist:  0.07303753042624832
--------------------------------------------------
COST: 1.3730
STEP: 13
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
-0.4668058832907908
goal dist:  0.0912862678240673
--------------------------------------------------
COST: 1.0913
STEP: 10
GOAL: True
Cost Mean: 2.4533
Cost Variance: 13.0420
cost_mean 2.45331535104285
cost_var 13.041983396641857
(tensor) yuzhou@Yuzhous-MacBook-Pro-8 bayesian_opt_multi_dynamic % 
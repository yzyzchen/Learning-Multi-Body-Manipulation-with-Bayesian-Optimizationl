(tensor) (base) yuzhou@Yuzhous-MacBook-Pro-8 bayesian_opt_multi_dynamic % python multi_dynamic_main.py opt_demo_model
pybullet build time: Nov  5 2024 13:54:07

=== Load the model and run the demo with bayes optimization===
argv[0]=--opengl2
/Users/yuzhou/Desktop/bayesian_opt_multi_dynamic/optimizer/panda_pushing_optimizer.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self._dynamics_model.load_state_dict(torch.load(BOX_MULTI_RESIDUAL_MODEL))
Testing box pushing optimizer with fixed target for 50 epochs
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.06938826970865605
--------------------------------------------------
COST: 1.5694
STEP: 15
GOAL: True
MIN COST: 1.5694
PARAM: ['0.1371', '0.1926', '0.5743', '0.4429']
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.19487466942574616
--------------------------------------------------
COST: 12.0949
STEP: 19
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.21351130684191297
--------------------------------------------------
COST: 12.2135
STEP: 20
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.13527886593000962
--------------------------------------------------
COST: 11.9353
STEP: 18
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.21964157001417642
--------------------------------------------------
COST: 11.5196
STEP: 13
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.15119748214154147
--------------------------------------------------
COST: 11.9512
STEP: 18
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.09353279706217621
--------------------------------------------------
COST: 1.4935
STEP: 14
GOAL: True
MIN COST: 1.4935
PARAM: ['0.1371', '0.1926', '0.5743', '0.4429']
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.07536300893717528
--------------------------------------------------
COST: 1.5754
STEP: 15
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.20819399821840912
--------------------------------------------------
COST: 12.3082
STEP: 21
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.13760565839977698
--------------------------------------------------
COST: 11.7376
STEP: 16
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.36110587187168924
--------------------------------------------------
COST: 11.0611
STEP: 7
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.0816156611033432
--------------------------------------------------
COST: 1.2816
STEP: 12
GOAL: True
MIN COST: 1.2816
PARAM: ['0.1371', '0.1926', '0.5743', '0.4429']
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.15998189176817865
--------------------------------------------------
COST: 12.0600
STEP: 19
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.34468057833981386
--------------------------------------------------
COST: 10.9447
STEP: 6
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.23899826115804926
--------------------------------------------------
COST: 12.4390
STEP: 22
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.08937426676920517
--------------------------------------------------
COST: 1.2894
STEP: 12
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.18401683337737232
--------------------------------------------------
COST: 11.6840
STEP: 15
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.09483118819459745
--------------------------------------------------
COST: 1.8948
STEP: 18
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.13105264629218635
--------------------------------------------------
COST: 14.0311
STEP: 39
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.20223602045629646
--------------------------------------------------
COST: 12.2022
STEP: 20
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.07306732677708465
--------------------------------------------------
COST: 1.6731
STEP: 16
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.09632235213425802
--------------------------------------------------
COST: 1.1963
STEP: 11
GOAL: True
MIN COST: 1.1963
PARAM: ['0.1371', '0.1926', '0.5743', '0.4429']
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.09670240738995042
--------------------------------------------------
COST: 1.3967
STEP: 13
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.19708026750471883
--------------------------------------------------
COST: 12.2971
STEP: 21
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.10290253930273667
--------------------------------------------------
COST: 1.2029
STEP: 11
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.2356033138466385
--------------------------------------------------
COST: 12.2356
STEP: 20
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.16124586707986052
--------------------------------------------------
COST: 11.5612
STEP: 14
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.10296741080199014
--------------------------------------------------
COST: 1.6030
STEP: 15
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.15616552216979038
--------------------------------------------------
COST: 11.9562
STEP: 18
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.1019401379663582
--------------------------------------------------
COST: 2.1019
STEP: 20
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.10538111120615713
--------------------------------------------------
COST: 1.5054
STEP: 14
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.29323919331371273
--------------------------------------------------
COST: 11.3932
STEP: 11
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.20766428255704872
--------------------------------------------------
COST: 12.3077
STEP: 21
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.2578085940363722
--------------------------------------------------
COST: 11.3578
STEP: 11
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.08577066156182395
--------------------------------------------------
COST: 1.2858
STEP: 12
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.1602715136114747
--------------------------------------------------
COST: 11.9603
STEP: 18
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.3196881586922829
--------------------------------------------------
COST: 11.5197
STEP: 12
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.206706840863612
--------------------------------------------------
COST: 11.6067
STEP: 14
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.3228049265385881
--------------------------------------------------
COST: 11.8228
STEP: 15
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.17277079551757227
--------------------------------------------------
COST: 11.6728
STEP: 15
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.09550425368936424
--------------------------------------------------
COST: 1.3955
STEP: 13
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.08332340089714967
--------------------------------------------------
COST: 1.7833
STEP: 17
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.08676722632087039
--------------------------------------------------
COST: 1.2868
STEP: 12
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.3046652619594246
--------------------------------------------------
COST: 11.4047
STEP: 11
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.08128579547146149
--------------------------------------------------
COST: 1.0813
STEP: 10
GOAL: True
MIN COST: 1.0813
PARAM: ['0.1371', '0.1926', '0.5743', '0.4429']
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.27434032899946453
--------------------------------------------------
COST: 12.0743
STEP: 18
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.2137446290119204
--------------------------------------------------
COST: 10.7137
STEP: 5
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.07682482284545653
--------------------------------------------------
COST: 1.1768
STEP: 11
GOAL: True
target state:  [ 0.95 -0.1   0.  ]
goal dist:  0.18368267998068455
--------------------------------------------------
COST: 12.0837
STEP: 19
GOAL: False
target state:  [ 0.95 -0.1   0.  ]
detached, done with this trajectory
goal dist:  0.3692060287341111
--------------------------------------------------
COST: 10.8692
STEP: 5
GOAL: False
Cost Mean: 7.8962
Cost Variance: 25.6165
cost_mean 7.896238569935845
cost_var 25.61647941479881
(tensor) (base) yuzhou@Yuzhous-MacBook-Pro-8 bayesian_opt_multi_dynamic % 